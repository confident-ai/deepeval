from deepeval.models.base_model import DeepEvalModelData

OPENAI_MODELS_DATA = {
    "gpt-3.5-turbo": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=0.50 / 1e6,
        output_price=1.50 / 1e6,
    ),
    "gpt-3.5-turbo-0125": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=0.50 / 1e6,
        output_price=1.50 / 1e6,
    ),
    "gpt-3.5-turbo-1106": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=1.00 / 1e6,
        output_price=2.00 / 1e6,
    ),
    "gpt-4-0125-preview": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=10.00 / 1e6,
        output_price=30.00 / 1e6,
    ),
    "gpt-4-1106-preview": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=10.00 / 1e6,
        output_price=30.00 / 1e6,
    ),
    "gpt-4-turbo": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=10.00 / 1e6,
        output_price=30.00 / 1e6,
    ),
    "gpt-4-turbo-2024-04-09": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=10.00 / 1e6,
        output_price=30.00 / 1e6,
    ),
    "gpt-4-turbo-preview": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=10.00 / 1e6,
        output_price=30.00 / 1e6,
    ),
    "gpt-4o": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=2.50 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gpt-4": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=30.00 / 1e6,
        output_price=60.00 / 1e6,
    ),
    "gpt-4o-2024-05-13": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=2.50 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gpt-4o-2024-08-06": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=2.50 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gpt-4o-2024-11-20": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=2.50 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gpt-4o-mini": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=0.150 / 1e6,
        output_price=0.600 / 1e6,
    ),
    "gpt-4o-mini-2024-07-18": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=0.150 / 1e6,
        output_price=0.600 / 1e6,
    ),
    "gpt-4-32k": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=60.00 / 1e6,
        output_price=120.00 / 1e6,
    ),
    "gpt-4-32k-0613": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=60.00 / 1e6,
        output_price=120.00 / 1e6,
    ),
    "gpt-4.1": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=2.00 / 1e6,
        output_price=8.00 / 1e6,
    ),
    "gpt-4.1-mini": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=0.4 / 1e6,
        output_price=1.60 / 1e6,
    ),
    "gpt-4.1-nano": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=0.1 / 1e6,
        output_price=0.4 / 1e6,
    ),
    "gpt-4.5-preview": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=75.00 / 1e6,
        output_price=150.00 / 1e6,
    ),
    "gpt-4.5-preview-2025-02-27": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=75.00 / 1e6,
        output_price=150.00 / 1e6,
    ),
    # Reasoning models - require temperature=1 (no custom temperature)
    "o1": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=15.00 / 1e6,
        output_price=60.00 / 1e6,
    ),
    "o1-preview": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        input_price=15.00 / 1e6,
        output_price=60.00 / 1e6,
    ),
    "o1-2024-12-17": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=15.00 / 1e6,
        output_price=60.00 / 1e6,
    ),
    "o1-preview-2024-09-12": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=15.00 / 1e6,
        output_price=60.00 / 1e6,
    ),
    "o1-mini": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        supports_temperature=False,
        input_price=None,
        output_price=None,
    ),
    "o1-mini-2024-09-12": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        supports_temperature=False,
        input_price=None,
        output_price=None,
    ),
    "o3-mini": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=1.10 / 1e6,
        output_price=4.40 / 1e6,
    ),
    "o3-mini-2025-01-31": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=1.10 / 1e6,
        output_price=4.40 / 1e6,
    ),
    "o4-mini": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=1.10 / 1e6,
        output_price=4.40 / 1e6,
    ),
    "o4-mini-2025-04-16": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=1.10 / 1e6,
        output_price=4.40 / 1e6,
    ),
    "gpt-5": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=1.25 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gpt-5-2025-08-07": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=1.25 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gpt-5-mini": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=0.25 / 1e6,
        output_price=2.00 / 1e6,
    ),
    "gpt-5-mini-2025-08-07": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=0.25 / 1e6,
        output_price=2.00 / 1e6,
    ),
    "gpt-5-nano": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=0.05 / 1e6,
        output_price=0.40 / 1e6,
    ),
    "gpt-5-nano-2025-08-07": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=False,
        supports_temperature=False,
        input_price=0.05 / 1e6,
        output_price=0.40 / 1e6,
    ),
    "gpt-5-chat-latest": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=1.25 / 1e6,
        output_price=10.00 / 1e6,
    ),
}


ANTHROPIC_MODELS_DATA = {
    "claude-3-opus-20240229": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
    "claude-3-sonnet-20240229": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-3-haiku-20240307": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=0.25 / 1e6,
        output_price=1.25 / 1e6,
    ),
    "claude-3-5-sonnet-20240620": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-3-5-sonnet-20241022": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-3-5-haiku-20241022": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.00 / 1e6,
        output_price=5.00 / 1e6,
    ),
    "claude-3-7-sonnet-20250219": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-opus-4-20250514": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
    "claude-opus-4-1-20250805": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
    "claude-sonnet-4-20250514": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-sonnet-4-5-20250929": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-haiku-4-5-20251001": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.00 / 1e6,
        output_price=5.00 / 1e6,
    ),
    "claude-opus-4-5-20251124": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
    "claude-3-opus": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
    "claude-3-sonnet": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-3-haiku": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=False,
        supports_json=True,
        input_price=0.25 / 1e6,
        output_price=1.25 / 1e6,
    ),
    "claude-3-5-sonnet": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-3-5-haiku": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.00 / 1e6,
        output_price=5.00 / 1e6,
    ),
    "claude-opus-4": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
    "claude-sonnet-4": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-sonnet-4-5": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "claude-haiku-4-5": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.00 / 1e6,
        output_price=5.00 / 1e6,
    ),
    "claude-opus-4-5": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=15.00 / 1e6,
        output_price=75.00 / 1e6,
    ),
}


GEMINI_MODELS_DATA = {
    "gemini-1.5-pro": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.25 / 1e6,
        output_price=5.00 / 1e6,
    ),
    "gemini-1.5-pro-002": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.25 / 1e6,
        output_price=5.00 / 1e6,
    ),
    "gemini-1.5-flash": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.075 / 1e6,
        output_price=0.30 / 1e6,
    ),
    "gemini-1.5-flash-002": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.075 / 1e6,
        output_price=0.30 / 1e6,
    ),
    "gemini-1.5-flash-8b": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.0375 / 1e6,
        output_price=0.15 / 1e6,
    ),
    "gemini-2.0-flash": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.15 / 1e6,
        output_price=0.60 / 1e6,
    ),
    "gemini-2.0-flash-lite": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.075 / 1e6,
        output_price=0.30 / 1e6,
    ),
    "gemini-2.5-pro": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.25 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gemini-2.5-flash": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.15 / 1e6,
        output_price=0.60 / 1e6,
    ),
    "gemini-2.5-flash-lite": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.075 / 1e6,
        output_price=0.30 / 1e6,
    ),
    "gemini-3-pro": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.25 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gemini-3-pro-preview": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.25 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "gemini-pro": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.50 / 1e6,
        output_price=1.50 / 1e6,
    ),
    "gemini-pro-vision": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.50 / 1e6,
        output_price=1.50 / 1e6,
    ),
}


GROK_MODELS_DATA = {
    "grok-3": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "grok-4": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "grok-4-fast": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.20 / 1e6,
        output_price=0.50 / 1e6,
    ),
    "grok-4-heavy": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "grok-4.1": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=3.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "grok-beta": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=5.00 / 1e6,
        output_price=15.00 / 1e6,
    ),
    "grok-2": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=2.00 / 1e6,
        output_price=10.00 / 1e6,
    ),
    "grok-2-mini": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.50 / 1e6,
        output_price=2.00 / 1e6,
    ),
    "grok-code-fast-1": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.20 / 1e6,
        output_price=1.50 / 1e6,
    ),
}


KIMI_MODELS_DATA = {
    "kimi-k2": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.58 / 1e6,
        output_price=2.29 / 1e6,
    ),
    "kimi-k2-instruct": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.58 / 1e6,
        output_price=2.29 / 1e6,
    ),
    "kimi-k2-base": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "moonshot-v1-8k": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.15 / 1e6,
        output_price=2.50 / 1e6,
    ),
    "moonshot-v1-32k": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.15 / 1e6,
        output_price=2.50 / 1e6,
    ),
    "moonshot-v1-128k": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.15 / 1e6,
        output_price=2.50 / 1e6,
    ),
}


DEEPSEEK_MODELS_DATA = {
    "deepseek-chat": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.028 / 1e6,
        output_price=0.42 / 1e6,
    ),
    "deepseek-v3.2": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.028 / 1e6,
        output_price=0.42 / 1e6,
    ),
    "deepseek-v3.2-exp": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.028 / 1e6,
        output_price=0.42 / 1e6,
    ),
    "deepseek-v3.1": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.14 / 1e6,
        output_price=0.28 / 1e6,
    ),
    "deepseek-v3": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.14 / 1e6,
        output_price=0.28 / 1e6,
    ),
    "deepseek-reasoner": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.14 / 1e6,
        output_price=2.19 / 1e6,
    ),
    "deepseek-r1": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.14 / 1e6,
        output_price=2.19 / 1e6,
    ),
    "deepseek-r1-lite": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.055 / 1e6,
        output_price=0.28 / 1e6,
    ),
    "deepseek-v2.5": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.14 / 1e6,
        output_price=0.28 / 1e6,
    ),
    "deepseek-coder": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.14 / 1e6,
        output_price=0.28 / 1e6,
    ),
    "deepseek-coder-6.7b": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=0.20 / 1e6,
        output_price=0.40 / 1e6,
    ),
    "deepseek-coder-33b": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=1.00 / 1e6,
        output_price=2.00 / 1e6,
    ),
}


OLLAMA_MODELS_DATA = {
    "qwen3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen3:8b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen3:14b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen3:30b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen3-vl": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen3-coder": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen2.5": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen2.5:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen2.5:14b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen2.5:32b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen2.5:72b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "qwen2.5-coder": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-r1": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-r1:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-r1:14b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-r1:32b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-r1:70b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-r1:671b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-v3.1": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-v3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-coder": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-coder:6.7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-coder:33b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "deepseek-coder-v2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma3:1b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma3:4b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma3:12b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma3:27b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma2:2b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma2:9b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "gemma2:27b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.3:70b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.2:1b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.2:3b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.2-vision": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.2-vision:11b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.2-vision:90b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.1": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.1:8b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.1:70b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3.1:405b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3:8b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama3:70b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama2:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama2:13b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama2:70b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llama4": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mistral": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mistral:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mistral-nemo": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mistral-small": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mistral-large": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mixtral": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mixtral:8x7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "mixtral:8x22b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "ministral-3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codestral": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "phi4": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "phi4:14b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "phi3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "phi3:3.8b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "phi3:14b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llava": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llava:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llava:13b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "llava:34b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "minicpm-v": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "moondream": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=True,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codellama": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codellama:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codellama:13b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codellama:34b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codellama:70b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "starcoder2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "starcoder2:3b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "starcoder2:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "starcoder2:15b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codegemma": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codegemma:2b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "codegemma:7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "tinyllama": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "tinyllama:1.1b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "smollm2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "smollm2:135m": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "smollm2:360m": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "smollm2:1.7b": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    # IBM Granite Models
    "granite4": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "granite3.3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "granite3.1-moe": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "granite-code": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    # Embedding Models
    "nomic-embed-text": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=None,
        output_price=None,
    ),
    "mxbai-embed-large": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=None,
        output_price=None,
    ),
    "bge-m3": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=None,
        output_price=None,
    ),
    "bge-large": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=None,
        output_price=None,
    ),
    "all-minilm": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=None,
        output_price=None,
    ),
    "snowflake-arctic-embed": DeepEvalModelData(
        supports_log_probs=False,
        supports_multimodal=False,
        supports_structured_outputs=False,
        supports_json=False,
        input_price=None,
        output_price=None,
    ),
    "dolphin3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "dolphin-llama3": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "dolphin-mixtral": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "orca-mini": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "orca2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "vicuna": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "nous-hermes2": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "command-r": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
    "command-r-plus": DeepEvalModelData(
        supports_log_probs=True,
        supports_multimodal=False,
        supports_structured_outputs=True,
        supports_json=True,
        input_price=None,
        output_price=None,
    ),
}
