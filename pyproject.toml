[tool.poetry]
name = "deepeval"
version = "2.5.8"
description = "The LLM Evaluation Framework"
authors = ["Jeffrey Ip <jeffreyip@confident-ai.com>"]
license = "Apache-2.0"
readme = "README.md"
repository = "https://github.com/confident-ai/deepeval"
documentation = "https://docs.confident-ai.com"

[tool.poetry.scripts]
deepeval = 'deepeval.cli.main:app'

[tool.poetry.plugins."pytest11"]
plugins = "deepeval.plugins.plugin"

[tool.poetry.dependencies]
python = ">=3.9, <4.0"
requests = "^2.31.0"
tqdm = "^4.66.1"
pytest = "^7.4.3"
pytest-xdist = "*"
pytest-repeat = "*"
pytest-rerunfailures = "^12.0"
pytest-asyncio = "^0.21.1"
tabulate = "^0.9.0"
sentry-sdk = "^1.33.1"
rich = "^13.6.0"
coverage = "*"
black = "*"
portalocker = "*"
openai = "*"
twine="5.1.1"
aiohttp = "*"
typer = "*"
instructor = "*"
ollama="*"
setuptools = "*"
wheel = "*"
langchain_openai = "*"
langchain_community = "*"
llama-index = "*"
tenacity = "<=9.0.0"
opentelemetry-api = "^1.24.0"  
opentelemetry-sdk = "^1.24.0" 
opentelemetry-exporter-otlp-proto-grpc = "^1.24.0" 
grpcio = "^1.67.1"

[tool.black]
line-length = 80

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.pytest.ini_options]
addopts = "-m 'not skip_test'"
markers = [
    "skip_test: skip the test",
]
