---
id: confident-ai-guardrails-privacy
title: Privacy Guard
sidebar_label: Privacy Guard
---

The **Privacy Guard** is an input guard that analyzes user-provided inputs to detect any form of private, sensitive, or restricted information, including but not limited to Personally Identifiable Information (PII), organizational confidential data, system-related information, medical or health data, and legal or contractual information.

:::info
`PrivacyGuard` is only available as an **input guard**.
:::

Here's what an unsafe input would look like in the context of privacy:

> _"Hi my name is Alex and I live on Maple Street 123"_
>
> _â€” probably a random user_

## Example

Since `PrivacyGuard` is a input guard, simply provide it as a guard in the list of `guards` when initializing a `Guardrails` object:

```python
from deepeval.guardrails import Guardrails, PrivacyGuard

guardrails = Guardrails(guards=[PrivacyGuard()])
```

Then, call the `guard_input` method to make use of the `PrivacyGuard`:

```python
...

guard_result = guardrails.guard_input(input=input)
print(guard_result)
```

:::note
There are no required arguments when initializing a `PrivacyGuard`.
:::

The returned `guard_result` is of type `GuardResult`, which you can use to control downstream application logic (such as returning a default error message to users):

```python
...

print(guard_result.breached, guard_result.guard_data)
```
