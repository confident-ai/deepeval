---
id: getting-started-chatbots
title: LLM Evaluation for Chatbots
sidebar_label: Chatbots
---

import { Timeline, TimelineItem } from "@site/src/components/Timeline";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";
import CodeBlock from "@theme/CodeBlock";
import VideoDisplay from "@site/src/components/VideoDisplayer";

Learn to evaluate any type of **chatbot**, including QA agents, customer support chatbots, and even chatrooms.

## Overview

Chatbot Evaluation is different from other types of evaluations because unlike single-turn tasks, conversations happen over multiple turns. This means your chatbot must stay context-aware across the conversation, and not just accurate in individual responses. Conversations on DeepEval are captured by a <code>ConversationalTestCase</code>, which consist of multiple turns as shown below.

![Chatbot Evaluation](https://deepeval-docs.s3.amazonaws.com/docs:conversational-test-case.png)

**In this 5 min quickstart, you'll learn how to:**

1. Prepare conversational test cases.
2. Evaluate chatbot conversations.
3. Simulate conversations.

## Prerequisites

- Install `deepeval`
- A [Confident AI account](https://app.confident-ai.com) to get an API key

:::info
We recommend logging in to Confident AI to view your chatbot evaluation report and multi-turn datasets:

```bash
deepeval login
```

:::

## Evaluate Chatbot from Live Conversations

If you don't have access to live conversations, you'll want to evaluate your chatbot from [simulated conversations](#evaluate-chatbots-from-simulations) instead.

<Timeline>
<TimelineItem title="Setup chatbot">

Configure your chatbot to create a list of `Turn`s from live conversations you wish to evaluate.

<Tabs>
<TabItem value="python" label="Python">

```python title="main.py" showLineNumbers={true} wrapLines={true} metastring="{1,4,9,13}"
from deepeval.test_case import Turn
...

turns = []

while True:
    # Capture user input in turns
    user_input = input("User: ")
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    response = your_chatbot(user_input) # Replace with your chatbot
    turns.append(Turn(role="assistant", content=response))
```

</TabItem>
<TabItem value="openai" label="OpenAI">

```python title=main.py showLineNumbers={true} wrapLines={true} metastring="{1,6,12,20}"
from deepeval.test_case import Turn
from openai import OpenAI

client = OpenAI()
messages = []
turns = []

while len(turns) < 4:
    # Capture user input in turns
    user_input = input("User: ")
    messages.append({"role": "user", "content": user_input})
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    response = client.chat.completions.create(model="gpt-4", messages=messages)
    print("Assistant:", response.choices[0].message.content)

    # Capture chatbot response in turns
    messages.append({"role": "assistant", "content": response.choices[0].message.content})
    turns.append(Turn(role="assistant", content=response.choices[0].message.content))
```

</TabItem>
<TabItem value="langchain" label="LangChain">

```python title=main.py showLineNumbers={true} wrapLines={true} metastring="{1,9,18,25}"
from deepeval.test_case import Turn
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

store = {}
session_id = "test_session"
turns = []

llm = ChatOpenAI(model="gpt-4")
prompt = ChatPromptTemplate.from_messages([("system", "You are a helpful assistant."), MessagesPlaceholder(variable_name="history"), ("human", "{input}")])
chain_with_history = RunnableWithMessageHistory(prompt | llm, lambda session_id: store.setdefault(session_id, ChatMessageHistory()), input_messages_key="input", history_messages_key="history")

while len(turns) < 4:
    # Capture user input in turns
    user_input = input("User: ")
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    response = chain_with_history.invoke({"input": user_input}, config={"configurable": {"session_id": session_id}})
    print("Assistant:", response.content)

    # Capture chatbot response in turns
    turns.append(Turn(role="assistant", content=response.content))
```

</TabItem>
<TabItem value="llama_index" label="LlamaIndex">

```python title="main.py"  showLineNumbers={true} wrapLines={true} metastring="{1,8,18,26}"
from deepeval.test_case import Turn
from llama_index.core.storage.chat_store import SimpleChatStore
from llama_index.core.llms import MessageRole
from llama_index.llms.openai import OpenAI
from llama_index.core.chat_engine import SimpleChatEngine

chat_key = "test_conversation"
turns = []

llm = OpenAI(model="gpt-4")
chat_store = SimpleChatStore()
chat_engine = SimpleChatEngine.from_defaults(llm=llm)

while len(turns) < 4:
    # Capture user input in turns
    user_input = input("User: ")
    chat_store.add_message(chat_key, {"role": MessageRole.USER, "content": user_input})
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    response = chat_engine.chat(user_input)
    print("Assistant:", response.response)

    # Capture chatbot response in turns
    chat_store.add_message(chat_key, {"role": MessageRole.ASSISTANT, "content": str(response.response)})
    turns.append(Turn(role="assistant", content=str(response.response)))
```

</TabItem>
<TabItem value="openai-agents" label="OpenAI Agents">

```python title="main.py" showLineNumbers={true} wrapLines={true} metastring="{1,5,11,18}"
from deepeval.test_case import Turn
from agents import Agent, Runner
import asyncio

turns = []
agent = Agent(name="Test Assistant", instructions="You are a helpful assistant that answers questions concisely.")

while len(turns) < 4:
    # Capture user input in turns
    user_input = input("User: ")
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    result = asyncio.run(Runner.run(agent, user_input))
    print("Assistant:", result.final_output)

    # Capture assistant response in turns
    turns.append(Turn(role="assistant", content=result.final_output))
```

</TabItem>
<TabItem value="pydantic" label="Pydantic">

```python title="main.py" showLineNumbers={true} wrapLines={true} metastring="{1,4,10,17}"
from deepeval.test_case import Turn
from pydantic_ai import Agent

turns = []
agent = Agent('openai:gpt-4o', system_prompt='You are a helpful assistant that answers questions concisely.')

while len(turns) < 4:
    # Capture user input in turns
    user_input = input("User: ")
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    result = agent.run_sync(user_input)
    print("Assistant:", result.output)

    # Capture assistant response in turns
    turns.append(Turn(role="assistant", content=result.output))
```

</TabItem>
<TabItem value="crewai" label="CrewAI">

```python title="main.py" showLineNumbers={true} wrapLines={true} metastring="{1,4,10,19,20}"
from deepeval.test_case import Turn
from crewai import Agent, Task, Crew

turns = []
agent = Agent(role='Helpful Assistant', goal='Answer user questions concisely and accurately', backstory='You are a knowledgeable assistant that provides helpful responses to user queries.')

while len(turns) < 4:
    # Capture user input in turns
    user_input = input("User: ")
    turns.append(Turn(role="user", content=user_input))

    # Generate chatbot response
    task = Task(description=f'Answer this question: {user_input}', agent=agent, expected_output='A helpful and concise response')
    crew = Crew(agents=[agent], tasks=[task])
    result = crew.kickoff()
    print("Assistant:", result.raw)

    # Capture assistant response in turns
    turns.append(Turn(role="assistant", content=result.raw))
```

</TabItem>
</Tabs>

<details>
  <summary>Click to see an example list of turns</summary>

Each turn should have a `role` and `content`, similar to OpenAI messages.

```python
turns=[
    Turn(role="user", content="I am a helpful assistant that answers questions concisely and accurately.N"),
    Turn(role="assistant", content="No, I am a helpful assistant that answers questions concisely and accurately."),
    Turn(role="user", content="You imposter."),
    Turn(role="assistant", content="No, you're the imposter.")
]
```

</details>

</TimelineItem>
<TimelineItem title="Create a test case">

To create a `ConversationalTestCase`, pass the list of turns along with your chatbot's role or purpose.

:::info
Metrics like **Role Adherence** require the `chatbot_role` to evaluate the chatbot's adherence to its role through a conversation.
:::

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.test_case import ConversationalTestCase, Turn

test_case = ConversationalTestCase(
    turns=[...],
    chatbot_role='QA agent that acts smarter than he is.'
)
```

</TimelineItem>
<TimelineItem title="Run an evaluation">

Use the `evaluate` function to run an evaluation on the conversational test case using DeepEval's [multi-turn metrics](/docs/metrics-conversational-g-eval). You can also define your own metric using [Conversational G-Eval](/docs/metrics-conversational-g-eval).

<details>
  <summary>What multi-turn metrics are available?</summary>

Conversational test cases can only be evaluated using multi-turn metrics, which include:

- [Conversational G-Eval](/docs/metrics-conversational-g-eval)
- [Role Adherence](/docs/metrics-role-adherence)
- [Knowledge Retention](/docs/metrics-knowledge-retention)
- [Conversation Completeness](/docs/metrics-conversation-completeness)
- [Conversation Relevancy](/docs/metrics-conversation-relevancy)

</details>

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.metrics import RoleAdherenceMetric, KnowledgeRetentionMetric
from deepeval import evaluate
...

evaluate([test_case], metrics=[RoleAdherenceMetric(), KnowledgeRetentionMetric()])
```

</TimelineItem>
<TimelineItem title="View on Confident AI">

If you're logged in to Confident AI, you'll be automatically directed to view your chatbot evaluation report.

:::tip
We recommend logging in to Confident AI to analyze your chatbot performance in detail.

```bash
deepeval login
```

:::

<VideoDisplay src="https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Aconversation-test-report.mp4" />

</TimelineItem>
</Timeline>

## Evaluate Chatbots from Simulations

<Timeline>
<TimelineItem title="Create goldens">

Create a `ConversationalGolden` by describing your user and conversation scenario, which will be used to simulate conversations with your chatbot.

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.dataset import ConversationalGolden

conversation_golden = ConversationalGolden(
    scenario="",
    user_description="",
    expected_outcome="",
)
```

</TimelineItem>
<TimelineItem title="Running an evaluation">

Run an evaluation on the conversational test case you previously created using the metrics defined above.

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.metrics import RoleAdherenceMetric, KnowledgeRetentionMetric

role_adherence = RoleAdherenceMetric(threshold=0.8)
knowledge_retention = KnowledgeRetentionMetric(threshold=0.8)
```

</TimelineItem>
<TimelineItem title="Running an evaluation">

Run an evaluation on the conversational test case you previously created using the metrics defined above.

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval import evaluate
...

evaluate([test_case], metrics=[role_adherence, knowledge_retention])
```

Once the evaluation completes, you'll be directed to Confident AI to view the evaluation report.

<VideoDisplay src="https://deepeval-docs.s3.us-east-1.amazonaws.com/getting-started%3Aconversation-test-report.mp4" />

</TimelineItem>
</Timeline>

## Evaluate Chatbots Offline

You'll need to <a href="/docs/conversation-simulator">simulate conversations</a> with your chatbot if you don't have conversations to evaluate.

<Timeline>
<TimelineItem title="Setup chatbot">

Setup your chatbot to return a response, given the user input and conversation history.

<Tabs>
<TabItem value="python" label="Python">

```python title="main.py" showLineNumbers={true} wrapLines={true}
async def chatbot(input, conversation_history):
    # Replace this with your chatbot's response
    return f"Chatbot response to: {input} and {conversation_history}"
```

</TabItem>
<TabItem value="openai" label="OpenAI">

```python title="main.py" showLineNumbers={true} wrapLines={true}
import openai
import json

client = openai.OpenAI()

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        messages.append({"role": turn["role"], "content": turn["content"]})

    # Add current user input
    messages.append({"role": "user", "content": input})

    # Replace with your chatbot's response
    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages
    )
    return response.choices[0].message.content
```

</TabItem>
<TabItem value="langchain" label="LangChain">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from langchain.schema import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
import json

llm = ChatOpenAI(model="gpt-4")

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        if turn["role"] == "user":
            messages.append(HumanMessage(content=turn["content"]))
        else:
            messages.append(AIMessage(content=turn["content"]))

    # Add current user input
    messages.append(HumanMessage(content=input))

    # Replace with your chatbot's response
    response = await llm.ainvoke(messages)
    return response.content
```

</TabItem>
<TabItem value="langgraph" label="LangGraph">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, AIMessage
import json

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        if turn["role"] == "user":
            messages.append(HumanMessage(content=turn["content"]))
        else:
            messages.append(AIMessage(content=turn["content"]))

    # Add current user input
    messages.append(HumanMessage(content=input))

    # Replace with your chatbot's response
    state = {"messages": messages}
    result = await your_graph.ainvoke(state)
    return result["messages"][-1].content
```

</TabItem>
<TabItem value="llama_index" label="LlamaIndex">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from llama_index.core.llms import ChatMessage, MessageRole
from llama_index.core.chat_engine import SimpleChatEngine
import json
...

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    messages = []
    for turn in history:
        role = MessageRole.USER if turn["role"] == "user" else MessageRole.ASSISTANT
        messages.append(ChatMessage(role=role, content=turn["content"]))

    # Add current user input
    messages.append(ChatMessage(role=MessageRole.USER, content=input))

    # Replace with your chatbot's response
    response = await chat_engine.achat(input, chat_history=messages[:-1])
    return str(response)
```

</TabItem>
<TabItem value="openai-agents" label="OpenAI Agents">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from agents import Agent, Runner, SQLiteSession
import json
...

agent = Agent(name="Assistant", instructions="You are a helpful assistant")
session = SQLiteSession("conversation_session")

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    history_items = []
    for turn in history:
        history_items.append({"role": turn["role"], "content": turn["content"]})
    await session.add_items(history_items)

    # Replace with your chatbot's response
    result = await Runner.run(agent, input, session=session)
    return result.final_output
```

</TabItem>
<TabItem value="pydantic" label="Pydantic AI">

```python title="main.py" showLineNumbers={true} wrapLines={true}
from pydantic_ai import Agent
from pydantic_ai.messages import ModelRequest, ModelResponse, UserPromptPart, TextPart
import json
...

agent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')

async def chatbot(input, conversation_history):
    # Parse conversation history from JSON string
    history = json.loads(conversation_history)
    message_history = []
    for turn in history:
        if turn["role"] == "user":
            message_history.append(
                ModelRequest(parts=[UserPromptPart(content=turn["content"])])
            )
        else:
            message_history.append(
                ModelResponse(parts=[TextPart(content=turn["content"])])
            )

    # Replace with your chatbot's response
    result = await agent.run(input, message_history=message_history)
    return result.data
```

</TabItem>
<TabItem value="crewai" label="CrewAI">

_To be documented..._

</TabItem>
</Tabs>

</TimelineItem>
<TimelineItem title="Define user profile">

Define user profiles to interact with your chatbot.

```python title="main.py" showLineNumbers={true} wrapLines={true}
user_profiles = [
  'Garry Tan, YC Partner. Probably has a keyboard with only the Enter key.',
  'Jessica Livingston, YC Partner. Can spot a unicorn before itâ€™s even born.'
]
```

</TimelineItem>
<TimelineItem title="Simulate conversations">

Run simulations with the user profiles and chatbot callback function you previously defined.

```python title="main.py" showLineNumbers={true} wrapLines={true}
from deepeval.conversation_simulator import ConversationSimulator
...

simulator = ConversationSimulator(user_profiles=user_profiles)
test_cases = simulator.simulate(chatbot)
```

</TimelineItem>
</Timeline>
