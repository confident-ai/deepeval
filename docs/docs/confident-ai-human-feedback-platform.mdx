---
id: confident-ai-human-feedback-platform
title: Managing Human Feedback
sidebar_label: Managing Human Feedback
---

The **Human Feedback** page serves as a central hub where engineers and reviewers can evaluate feedback from reviewers and users to improve LLM performance. By systematically reviewing feedback, you can identify failing patterns, gather insights, and make data-driven decisions to enhance your LLM’s responses in production.

## Leaving a feedback

### 1.) Human Feedback Page

Navigate to the Human Feedback page. Here, you will find both reviewer-provided feedback and user-provided feedback (sent through `deepeval`).

![ok](https://confident-bucket.s3.amazonaws.com/human_feedback.svg)

### 2.) Filtering Feedback

You can filter feedback based on various criteria, such as rating, feedback provider (reviewer or user), explanation, and expected response. Filtering for low-rated responses can help you identify common failing themes in your LLM’s outputs.

![ok](https://confident-bucket.s3.amazonaws.com/human_feedback_filter.svg)

### 3.) Viewing Filtered Feedback

For example, you can view all 1-star rated feedback to analyze areas that need improvement.

![ok](https://confident-bucket.s3.amazonaws.com/human_feedback_filtered.svg)
